% ----------------------------------------------- %
%
\section{Preliminaries} \label{sec:prelim}
%
% ----------------------------------------------- %


SUMMARY OF THE SECTION - TO BE DELETED BEFORE SUBMISSION:
\begin{itemize}
\item Common Definifions:

Set of Features

Feature Space

\item ML Problems considered:
\begin{itemize}
\item Classification problems:

Set of Classes

Classification function

MC -  Classification model

\item Regression problems:

Codomain

Regression function

MR - Regression model

\item General Model:
\end{itemize}

\item instance (v, c)

Goal: to compute explanations for (v, c)

\end{itemize}


% ----------------------------------------------- %

This section provides the basic notation used throughout the paper.
%
The goal is to provide explanations to ML models.
%
These are defined on a set of $m$ features (or attributes) $\fml{F}=\{1,\ldots,m\}$.
%
Each feature $i\in \fml{F}$ takes values from its associated domain $D_i$.
%
Domains can be categorical or ordinal, with values that can be Boolean, integer or real.
%
The feature space $\mbb{F}$ is defined by the Cartesian product of the domains as $\mbb{F}=D_1\times\ldots\times D_m$.
%
The notation $\mbf{x}=(x_1,\ldots,x_m)$ represents an arbitrary point in the feature space, where each $x_i$ is a variable taking values from $D_i$.
%
Moreover, $\mbf{v}=(v_1,\ldots,v_m)$ represents a specific point in the feature space, where each $v_i$ is such that $v_i \in D_i$ (a concrete value).

In the paper, the ML models considered are either Classification or Regression ML models described in the following paragraphs.

% ----------------------------------------------- %
\paragraph{Classification Problems.}

Classification problems are ML models that besides the set of features are defined on set of $K$ classes $\mbb{K}=\{c_1,\ldots,c_K\}$.
%
An ML classifier $\fml{M}_C$ is characterized by a (non-constant) classification function $\kappa:\mbb{F}\to\mbb{K}$ mapping feature space points into classes.
%
A classifier $\fml{M}_C$ is represented by the tuple $\fml{M}_C=(\fml{F}, \mbb{F}, \mbb{K}, \kappa)$.
%
Observe that, the classification function represents the operation (or behaviour) of the ML classifier, i.e. the machine learning model.


Given a classifier $\fml{M}_C$, a point $\mbf{v}\in\mbb{F}$, and a class $c\in\mbb{K}$ such that $c=\kappa(v)$, an instance (for the classifier) is defined as $(\mbf{v},c)$.

% ----------------------------------------------- %
\paragraph{Regression Problems.}

Regression problems are ML models defined on the set of features and consider a (non-constant) regression function $\rho:\mbb{F}\to\mbb{V}$, where $\mbb{V}$ is a continuous set (codomain of $\rho$).
%
A regression model $\fml{M}_R$ is represented by the tuple $\fml{M}_R=(\fml{F}, \mbb{F}, \mbb{V}, \rho)$.


Given a regression model $\fml{M}_R$, a point $\mbf{v}\in\mbb{F}$, and a value $q\in\mbb{V}$ such that $q=\rho(v)$, an instance (for the regression) is defined as $(\mbf{v},q)$.


% ----------------------------------------------- %
\paragraph{General Problem Formulation.}

Classification and Regression problems are generalized into a General Problem  Formulation.
%
A General Problem Formulation is defined by the set of features $\fml{F}$ and a range $\mbb{T}$ of possible predictions.
%
Additionally, a non-constant function $\tau:\fml{F}\to\mbb{T}$ maps feature space points into possible prediction outcomes.


A General model $\fml{M}$ is represented by the tuple $\fml{M}=(\fml{F}, \mbb{F}, \mbb{T}, \tau)$.
%
Similarly, given a model $\fml{M}$, a point $\mbf{v}\in\mbb{F}$, and a value $q\in\mbb{T}$ such that $q=\tau(v)$, an instance is defined as $(\mbf{v},q)$.


To be able to compare the prediction's outcome of a variable point $(\mbf{x})$ to the prediction of a given (constant) point $(\mbf{v}\in\mbb{F}$), it is advantageous to define the Similarity predicate $\sigma:\mbb{F}\to\{\top, \bot\}$.
%
In the case of Classification models, the Similarity predicate is defined as follows:
%
$$
\sigma(\mbf{x}):=[\kappa(\mbf{x}) = \kappa(\mbf{v})]
$$
%
In the case of Regression models, the Similarity predicate is defined as follows:
%
$$
\sigma(\mbf{x}):=[|\rho(\mbf{x}) - \rho(\mbf{v})| \leq \delta]
$$
%
where $\delta$ is an additional user-specified parameter.
